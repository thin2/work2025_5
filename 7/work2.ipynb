{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T04:52:42.119059Z",
     "start_time": "2025-03-11T04:52:40.081282Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "HQD = pd.read_excel('HQD(1).xlsx')\n",
    "HQD = HQD.drop([0])\n",
    "\n",
    "# 提取从 A001101000 到 CO2 的列\n",
    "start_column = 'A001101000'\n",
    "end_column = 'CO2'\n",
    "\n",
    "# 直接提取指定范围的列\n",
    "HQD = HQD.loc[:, start_column:end_column]\n",
    "\n",
    "# 查看提取后的数据框\n",
    "HQD"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "64ed685bfb9af1ef",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T04:57:02.135322Z",
     "start_time": "2025-03-11T04:57:01.381678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 计算每列的平均值，忽略 NaN 值\n",
    "column_means = HQD.mean(skipna=True)\n",
    "\n",
    "# 将 NaN 值替换为每列的平均值\n",
    "HQD.fillna(column_means, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(HQD)  \n",
    "HQD2 = pd.DataFrame(scaler.transform(HQD))  \n",
    "HQD2 # 查看标准化后的数据列"
   ],
   "id": "e8cc8e92f912c4a8",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "d0f2e10f0ec36714",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T04:57:07.734973Z",
     "start_time": "2025-03-11T04:57:06.515926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.decomposition import PCA  \n",
    "pca = PCA(n_components=HQD2.shape[1]-1)  # 创建主成分分析对象，设定主成分数为样本特征数 - 1\n",
    "reduced_x = pca.fit_transform(HQD2)  # 基于已标准化数据创建主成分分析模型\n",
    "covper = pca.explained_variance_  # 降维后的各主成分的方差值\n",
    "covper = pd.DataFrame(np.round(covper, 3))  \n",
    "\n",
    "# 绘制碎石图\n",
    "plt.plot(covper, 'bx--')\n",
    "plt.xlabel('Component #n')\n",
    "plt.ylabel('Variance')\n",
    "plt.show()"
   ],
   "id": "c4e2a5f4f0caf855",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T04:57:11.786966Z",
     "start_time": "2025-03-11T04:57:11.603799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "coefficient=pd.DataFrame(np.round(pca.components_, 3),columns=HQD.columns)#输出载荷系数\n",
    "coefficient.to_excel('HQD_coefficient.xlsx')\n",
    "\n",
    "contribution=pd.DataFrame(np.round(pca.explained_variance_ratio_, 3) )#输出累计方差贡献率\n",
    "contribution.to_excel('HQD_contribution.xlsx')"
   ],
   "id": "3eb5ebe23545aa8d",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "pd.DataFrame(np.round(reduced_x, 3))"
   ],
   "id": "ad697d14d9ab8f00",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T12:36:40.734692Z",
     "start_time": "2025-03-11T12:36:32.587579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# ================== 配置区域 ==================\n",
    "input_file = 'HQD(1).xlsx'              # 原始数据文件\n",
    "industry_col = 'Sicda_str'                 # 行业分类列名（需存在于数据中）\n",
    "start_column = 'A001101000'          # 数据起始列\n",
    "end_column = 'CO2'                   # 数据结束列\n",
    "target_columns = ['A001101000', 'A001107000', 'A001110000']  # 目标分析列\n",
    "output_dir = '行业分析报告'         # 输出主目录\n",
    "# =============================================\n",
    "\n",
    "def calculate_weighted_scores(data_df, weights):\n",
    "    \"\"\"计算加权综合得分（核心逻辑）\"\"\"\n",
    "    # 验证目标列存在\n",
    "    missing_cols = set(target_columns) - set(data_df.columns)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"缺失目标列: {missing_cols}\")\n",
    "    \n",
    "  \n",
    "    weighted_scores = (data_df[target_columns] * weights[target_columns]).sum(axis=1)\n",
    "    \n",
    "    return weighted_scores.sum()\n",
    "\n",
    "def process_industry(group, industry_name, output_path):\n",
    "    \"\"\"处理单个行业分析\"\"\"\n",
    "    try:\n",
    "        # 创建目录\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        # 数据预处理\n",
    "        numeric_df = group.drop(columns=[industry_col]).apply(pd.to_numeric, errors='coerce')\n",
    "        numeric_df.fillna(numeric_df.mean(), inplace=True)\n",
    "        \n",
    "        # 标准化\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(numeric_df)\n",
    "        \n",
    "        # PCA分析\n",
    "        pca = PCA()\n",
    "        pca.fit(scaled_data)\n",
    "        \n",
    "        # 计算特征权重\n",
    "        feature_weights = pd.Series(\n",
    "            np.dot(pca.components_.T, pca.explained_variance_ratio_),\n",
    "            index=numeric_df.columns\n",
    "        )\n",
    "        \n",
    "        # 保存分析结果\n",
    "        save_analysis_results(pca, numeric_df.columns, output_path)\n",
    "        \n",
    "        # 计算行业加权得分\n",
    "        industry_score = calculate_weighted_scores(numeric_df, feature_weights)\n",
    "        return industry_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理行业 {industry_name} 时出错: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def save_analysis_results(pca, features, output_path):\n",
    "    \"\"\"保存分析结果\"\"\"\n",
    "    # 保存载荷矩阵\n",
    "    pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        index=features,\n",
    "        columns=[f'PC{i+1}' for i in range(pca.n_components_)]\n",
    "    ).to_excel(os.path.join(output_path, '载荷矩阵.xlsx'))\n",
    "    \n",
    "    # 保存方差贡献率\n",
    "    pd.DataFrame({\n",
    "        '方差贡献率': pca.explained_variance_ratio_,\n",
    "        '累计贡献率': np.cumsum(pca.explained_variance_ratio_)\n",
    "    }).to_excel(os.path.join(output_path, '方差贡献率.xlsx'))\n",
    "    \n",
    "    # 生成碎石图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(pca.explained_variance_ratio_, 'bo-')\n",
    "    plt.title('主成分方差解释率')\n",
    "    plt.savefig(os.path.join(output_path, '碎石图.png'))\n",
    "    plt.close()\n",
    "\n",
    "def visualize_industry_scores(scores):\n",
    "    \"\"\"可视化行业得分\"\"\"\n",
    "    # 准备数据\n",
    "    df_scores = pd.DataFrame.from_dict(scores, orient='index', columns=['综合得分'])\n",
    "    df_scores.sort_values('综合得分', ascending=False, inplace=True)\n",
    "    \n",
    "    # 绘制图表\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = df_scores['综合得分'].plot.barh(color='skyblue')\n",
    "    \n",
    "    # 装饰图表\n",
    "    plt.title('行业综合得分对比', fontsize=14)\n",
    "    plt.xlabel('得分', fontsize=12)\n",
    "    plt.ylabel('行业', fontsize=12)\n",
    "    plt.grid(axis='x', alpha=0.4)\n",
    "    \n",
    "    # 添加数据标签\n",
    "    for bar in bars.containers[0]:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.02, \n",
    "                bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.2f}', \n",
    "                va='center')\n",
    "    \n",
    "    # 保存结果\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, '行业得分对比.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # 加载数据\n",
    "    df = pd.read_excel(input_file, header=0, skiprows=[1])\n",
    "    data_cols = list(df.loc[:, start_column:end_column].columns) + [industry_col]\n",
    "    df = df[data_cols]\n",
    "    \n",
    "    # 按行业处理\n",
    "    industry_scores = {}\n",
    "    for industry, group in df.groupby(industry_col):\n",
    "        dir_path = os.path.join(output_dir, str(industry))\n",
    "        score = process_industry(group, industry, dir_path)\n",
    "        if score is not None:\n",
    "            industry_scores[industry] = score\n",
    "    \n",
    "    # 可视化结果\n",
    "    if industry_scores:\n",
    "        visualize_industry_scores(industry_scores)\n",
    "        print(f\"分析完成！结果已保存至: {os.path.abspath(output_dir)}\")\n",
    "    else:\n",
    "        print(\"未生成有效得分\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "17864303d8c81e57",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T05:54:08.121753Z",
     "start_time": "2025-03-11T05:53:48.814055Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e8208e2b3756d3f7",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "f2296191b1017497",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
