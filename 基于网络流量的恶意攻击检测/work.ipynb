{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-04T10:28:04.348879Z",
     "start_time": "2025-05-04T10:28:02.553510Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('train_data.csv')\n",
    "df.info()"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T10:30:40.951226Z",
     "start_time": "2025-05-04T10:30:40.617347Z"
    }
   },
   "cell_type": "code",
   "source": "df.describe(include='all')",
   "id": "f5ca485dc6e38bcb",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T10:32:32.493410Z",
     "start_time": "2025-05-04T10:32:32.485081Z"
    }
   },
   "cell_type": "code",
   "source": "object1=df.select_dtypes(include=['object'])",
   "id": "bed8cc575372a78d",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T10:32:34.338241Z",
     "start_time": "2025-05-04T10:32:34.277233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for column in object1.columns:\n",
    "    print(column)\n",
    "    print(object1[column].unique())"
   ],
   "id": "50fff802a5baaaf0",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T10:41:54.535034Z",
     "start_time": "2025-05-04T10:41:43.305362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('train_data.csv')\n",
    "\n",
    "# 编码类别字段\n",
    "cat_cols = ['proto', 'service', 'state']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 编码标签字段\n",
    "label_le = LabelEncoder()\n",
    "df['attack_cat'] = label_le.fit_transform(df['attack_cat'])\n",
    "\n",
    "# 特征列\n",
    "features = df.columns.difference(['id', 'attack_cat'])\n",
    "\n",
    "# 划分训练/验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[features], df['attack_cat'], test_size=0.3, random_state=42, stratify=df['attack_cat']\n",
    ")\n",
    "\n",
    "# 初始化 LGBM 模型\n",
    "model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=len(label_le.classes_),\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=64,\n",
    "    max_depth=-1,\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "# 训练模型，使用 callbacks 替代 early_stopping_rounds\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[early_stopping(stopping_rounds=10), log_evaluation(0)]\n",
    ")\n",
    "\n",
    "# 预测验证集\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# 打印准确率\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(f'验证集准确率: {acc:.4f}')\n",
    "\n",
    "# 打印模型参数\n",
    "print('模型参数:')\n",
    "print(model.get_params())\n"
   ],
   "id": "51cce4aaae2f699c",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T10:53:30.656300Z",
     "start_time": "2025-05-04T10:53:21.640635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "# === 1. 读取训练数据 ===\n",
    "df = pd.read_csv('train_data.csv')\n",
    "\n",
    "# 需要编码的类别字段\n",
    "cat_cols = ['proto', 'service', 'state']\n",
    "label_encoders = {}\n",
    "\n",
    "# 编码类别字段\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 编码标签列\n",
    "label_le = LabelEncoder()\n",
    "df['attack_cat'] = label_le.fit_transform(df['attack_cat'])\n",
    "\n",
    "# 特征列（排除 id 和标签）\n",
    "features = df.columns.difference(['id', 'attack_cat'])\n",
    "\n",
    "# === 2. 划分训练集和验证集 ===\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[features], df['attack_cat'], test_size=0.3, random_state=42, stratify=df['attack_cat']\n",
    ")\n",
    "\n",
    "# === 3. 定义并训练 LightGBM 模型 ===\n",
    "model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=len(label_le.classes_),\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=64,\n",
    "    max_depth=-1,\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[early_stopping(stopping_rounds=10), log_evaluation(0)]\n",
    ")\n",
    "\n",
    "# === 4. 验证集评估 ===\n",
    "y_pred_val = model.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred_val)\n",
    "print(f'验证集准确率: {acc:.4f}')\n",
    "print('模型参数:')\n",
    "print(model.get_params())\n",
    "\n",
    "# === 5. 读取测试集并做同样的预处理 ===\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# 编码测试集的类别特征（使用训练集的编码器）\n",
    "for col in cat_cols:\n",
    "    le = label_encoders[col]\n",
    "    mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "    df_test[col] = df_test[col].map(mapping).fillna(-1).astype(int)\n",
    "\n",
    "\n",
    "# 特征列\n",
    "X_test = df_test[features]\n",
    "\n",
    "# === 6. 模型预测测试集 ===\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_labels = label_le.inverse_transform(y_test_pred)  # 反编码为原始标签\n",
    "\n",
    "# === 7. 输出或保存预测结果 ===\n",
    "df_test['predicted_attack_cat'] = y_test_labels\n",
    "df_test[['id', 'predicted_attack_cat']].to_csv('test_predictions.csv', index=False)\n",
    "print(\"测试集预测完成，结果已保存到 test_predictions.csv\")\n"
   ],
   "id": "1eca9c42344b477c",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T12:36:07.678533Z",
     "start_time": "2025-05-04T12:35:55.114363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "# === 1. 读取训练数据 ===\n",
    "df = pd.read_csv('train_data.csv')\n",
    "\n",
    "# 编码类别字段\n",
    "cat_cols = ['proto', 'service', 'state']\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 编码标签列\n",
    "label_le = LabelEncoder()\n",
    "df['attack_cat'] = label_le.fit_transform(df['attack_cat'])\n",
    "\n",
    "# 特征列（排除 id 和标签）\n",
    "features = df.columns.difference(['id', 'attack_cat','ct_ftp_cmd','is_sm_ips_ports','trans_depth','swin','is_ftp_login','dwin'])\n",
    "\n",
    "# === 2. 特征标准化 ===\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "# === 3. 划分训练集和验证集 ===\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[features], df['attack_cat'], test_size=0.3, random_state=42, stratify=df['attack_cat']\n",
    ")\n",
    "\n",
    "# === 4. 定义并训练 LightGBM 模型 ===\n",
    "model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=len(label_le.classes_),\n",
    "    learning_rate=0.2,\n",
    "    num_leaves=64,\n",
    "    max_depth=-1,\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    reg_alpha=0.5,   # 加入L1正则\n",
    "    reg_lambda=2.0   # 加入L2正则\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[early_stopping(stopping_rounds=10), log_evaluation(0)]\n",
    ")\n",
    "\n",
    "# === 5. 验证集评估 ===\n",
    "y_pred_val = model.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred_val)\n",
    "print(f'验证集准确率: {acc:.4f}')\n",
    "print('模型参数:')\n",
    "print(model.get_params())\n",
    "\n",
    "# === 6. 读取测试集并预处理 ===\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# 类别特征编码\n",
    "for col in cat_cols:\n",
    "    le = label_encoders[col]\n",
    "    mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "    df_test[col] = df_test[col].map(mapping).fillna(-1).astype(int)\n",
    "\n",
    "# 特征标准化（使用训练集的 scaler）\n",
    "df_test[features] = scaler.transform(df_test[features])\n",
    "\n",
    "# === 7. 模型预测测试集 ===\n",
    "X_test = df_test[features]\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_labels = label_le.inverse_transform(y_test_pred)\n",
    "\n",
    "# === 8. 输出结果 ===\n",
    "df_test['attack_cat'] = y_test_labels\n",
    "df_test[['id', 'attack_cat']].to_csv('test_predictions.csv', index=False)\n",
    "print(\"测试集预测完成，结果已保存到 test_predictions.csv\")\n"
   ],
   "id": "977313b970e30b14",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T12:27:33.820661Z",
     "start_time": "2025-05-04T12:27:31.100616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === 4.1 打印特征重要性 ===\n",
    "feature_importance = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n各特征的重要性（按降序排列）：\")\n",
    "print(feature_importance)\n",
    "\n",
    "# 可选：画图可视化特征重要性\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance.head(35).plot(kind='bar')\n",
    "plt.title(\"Top 20 Feature Importances\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "bf1cc397fb7ae220",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T04:16:51.402906Z",
     "start_time": "2025-05-17T04:13:29.800706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "\n",
    "# ================== 数据加载与特征工程 ==================\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    df['bytes_ratio']   = df['sbytes'] / (df['dbytes'] + 1e-6)\n",
    "    df['pkts_ratio']    = df['spkts'] / (df['dpkts'] + 1e-6)\n",
    "    df['flow_rate']     = (df['sbytes'] + df['dbytes']) / (df['dur'] + 1e-6)\n",
    "    df['pkt_size_diff'] = df['spkts'] - df['dpkts']\n",
    "    df['byte_per_pkt']  = (df['sbytes'] + df['dbytes']) / (df['spkts'] + df['dpkts'] + 1e-6)\n",
    "    df['total_bytes']   = df['sbytes'] + df['dbytes']\n",
    "    df['total_pkts']    = df['spkts'] + df['dpkts']\n",
    "    df['bytes_per_sec'] = df['total_bytes'] / (df['dur'] + 1e-6)\n",
    "    df['pkts_per_sec']  = df['total_pkts'] / (df['dur'] + 1e-6)\n",
    "    return df\n",
    "\n",
    "train = pd.read_csv('train_data.csv')\n",
    "test  = pd.read_csv('test_data.csv')\n",
    "train = feature_engineering(train)\n",
    "test  = feature_engineering(test)\n",
    "\n",
    "# 处理分类特征\n",
    "categorical_cols = ['proto', 'service', 'state']\n",
    "for df in (train, test):\n",
    "    df[categorical_cols] = df[categorical_cols].replace('-', 'unknown')\n",
    "\n",
    "# 标签编码\n",
    "classes = ['Generic','Reconnaissance','Normal','DoS','Fuzzers',\n",
    "           'Worms','Backdoor','Analysis','Shellcode','Exploits']\n",
    "le = LabelEncoder()\n",
    "train['attack_cat'] = train['attack_cat'].map(lambda x: x if x in classes else 'Normal')\n",
    "y = le.fit_transform(train['attack_cat'])\n",
    "\n",
    "# 特征和预处理\n",
    "X = train.drop(['id','attack_cat'], axis=1)\n",
    "X_test = test.drop('id', axis=1)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "], remainder='passthrough')\n",
    "X = preprocessor.fit_transform(X)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# 划分训练/验证集并计算样本权重\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "sample_weights = class_weights[y]\n",
    "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(\n",
    "    X, y, sample_weights,\n",
    "    test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, weight=w_train)\n",
    "dval   = xgb.DMatrix(X_val,   label=y_val,   weight=w_val)\n",
    "\n",
    "def train_model(params, dtrain, dval, num_round=2000, early_stopping=50):\n",
    "    evals = [(dtrain, 'train'), (dval, 'valid')]\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_round,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=early_stopping,\n",
    "        verbose_eval=50\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 定义参数列表\n",
    "param_list = [\n",
    "    {'objective':'multi:softprob','num_class':len(classes),'tree_method':'hist',\n",
    "     'learning_rate':0.05,'max_depth':8,'min_child_weight':3,'gamma':0.3,\n",
    "     'reg_alpha':1.0,'reg_lambda':2.0,'subsample':0.7,'colsample_bytree':0.6,\n",
    "     'eval_metric':'mlogloss','n_jobs':-1,'random_state':42,'verbosity':0},\n",
    "    {'objective':'multi:softprob','num_class':len(classes),'tree_method':'hist',\n",
    "     'learning_rate':0.03,'max_depth':10,'min_child_weight':2,'gamma':0.2,\n",
    "     'reg_alpha':0.5,'reg_lambda':1.5,'subsample':0.8,'colsample_bytree':0.7,\n",
    "     'eval_metric':'mlogloss','n_jobs':-1,'random_state':42,'verbosity':0},\n",
    "    {'objective':'multi:softprob','num_class':len(classes),'tree_method':'hist',\n",
    "     'learning_rate':0.07,'max_depth':6,'min_child_weight':4,'gamma':0.4,\n",
    "     'reg_alpha':1.5,'reg_lambda':2.5,'subsample':0.6,'colsample_bytree':0.5,\n",
    "     'eval_metric':'mlogloss','n_jobs':-1,'random_state':42,'verbosity':0},\n",
    "]\n",
    "\n",
    "# 训练模型\n",
    "models = []\n",
    "for params in param_list:\n",
    "    models.append(train_model(params, dtrain, dval))\n",
    "\n",
    "# 验证集软投票\n",
    "proba_val = sum(m.predict(dval) for m in models) / len(models)\n",
    "pred_val = np.argmax(proba_val, axis=1)\n",
    "f1 = f1_score(y_val, pred_val, average='macro')\n",
    "print(f\"Ensemble Validation Macro F1: {f1:.4f}\")\n",
    "\n",
    "# 测试集预测\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "proba_test = sum(m.predict(dtest) for m in models) / len(models)\n",
    "pred_test = np.argmax(proba_test, axis=1)\n",
    "pred_cat = le.inverse_transform(pred_test)\n",
    "\n",
    "# 保存结果与模型\n",
    "pd.DataFrame({'id': test['id'], 'attack_cat': pred_cat})\\\n",
    "    .to_csv('ensemble_xgb_predictions.csv', index=False)\n",
    "joblib.dump(preprocessor, 'ensemble_xgb_preprocessor.pkl')\n",
    "for idx, m in enumerate(models):\n",
    "    m.save_model(f'xgb_model_{idx}.model')\n",
    "print(\"Prediction and models saved.\")\n"
   ],
   "id": "4efa5e7b58f1afc9",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T04:52:37.352799Z",
     "start_time": "2025-05-17T04:37:42.565727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "\n",
    "# ================== 数据加载与特征工程 ==================\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    df['bytes_ratio']   = df['sbytes'] / (df['dbytes'] + 1e-6)\n",
    "    df['pkts_ratio']    = df['spkts'] / (df['dpkts'] + 1e-6)\n",
    "    df['flow_rate']     = (df['sbytes'] + df['dbytes']) / (df['dur'] + 1e-6)\n",
    "    df['pkt_size_diff'] = df['spkts'] - df['dpkts']\n",
    "    df['byte_per_pkt']  = (df['sbytes'] + df['dbytes']) / (df['spkts'] + df['dpkts'] + 1e-6)\n",
    "    df['total_bytes']   = df['sbytes'] + df['dbytes']\n",
    "    df['total_pkts']    = df['spkts'] + df['dpkts']\n",
    "    df['bytes_per_sec'] = df['total_bytes'] / (df['dur'] + 1e-6)\n",
    "    df['pkts_per_sec']  = df['total_pkts'] / (df['dur'] + 1e-6)\n",
    "    return df\n",
    "\n",
    "train = pd.read_csv('train_data.csv')\n",
    "test  = pd.read_csv('test_data.csv')\n",
    "train = feature_engineering(train)\n",
    "test  = feature_engineering(test)\n",
    "\n",
    "# 分类特征预处理\n",
    "categorical_cols = ['proto','service','state']\n",
    "for df in (train,test):\n",
    "    df[categorical_cols] = df[categorical_cols].replace('-', 'unknown')\n",
    "\n",
    "# 标签与样本权重\n",
    "classes = ['Generic','Reconnaissance','Normal','DoS','Fuzzers','Worms','Backdoor','Analysis','Shellcode','Exploits']\n",
    "le = LabelEncoder()\n",
    "train['attack_cat'] = train['attack_cat'].map(lambda x: x if x in classes else 'Normal')\n",
    "y = le.fit_transform(train['attack_cat'])\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "sample_weights = class_weights[y]\n",
    "\n",
    "# 特征编码\n",
    "X = train.drop(['id','attack_cat'], axis=1)\n",
    "X_test = test.drop('id', axis=1)\n",
    "preprocessor = ColumnTransformer([('ohe', OneHotEncoder(handle_unknown='ignore'), categorical_cols)], remainder='passthrough')\n",
    "X = preprocessor.fit_transform(X)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# 划分训练/验证集\n",
    "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(\n",
    "    X, y, sample_weights, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 定义并训练各模型\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softprob', num_class=len(classes),\n",
    "    learning_rate=0.02, max_depth=6,\n",
    "    subsample=0.6, colsample_bytree=0.5,\n",
    "    reg_alpha=5, reg_lambda=10,\n",
    "    n_estimators=1000, use_label_encoder=False,\n",
    "    eval_metric='mlogloss', random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "lgb_clf = LGBMClassifier(\n",
    "    objective='multiclass', num_class=len(classes),\n",
    "    learning_rate=0.02, max_depth=6,\n",
    "    subsample=0.6, colsample_bytree=0.5,\n",
    "    reg_alpha=5, reg_lambda=10,\n",
    "    n_estimators=1000, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "cat_clf = CatBoostClassifier(\n",
    "    loss_function='MultiClass', learning_rate=0.02, depth=6,\n",
    "    bootstrap_type='Bernoulli', subsample=0.6, reg_lambda=10,\n",
    "    iterations=1000, random_seed=42, verbose=100\n",
    ")\n",
    "\n",
    "# 逐模型训练，并传入样本权重（若支持）\n",
    "xgb_clf.fit(X_train, y_train, sample_weight=w_train)\n",
    "lgb_clf.fit(X_train, y_train, sample_weight=w_train)\n",
    "cat_clf.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "# 验证集概率与软投票\n",
    "proba_val = (2 * xgb_clf.predict_proba(X_val)\n",
    "            + 1 * lgb_clf.predict_proba(X_val)\n",
    "            + 1 * cat_clf.predict_proba(X_val)) / 4\n",
    "pred_val = np.argmax(proba_val, axis=1)\n",
    "print(classification_report(y_val, pred_val, target_names=le.classes_))\n",
    "f1 = f1_score(y_val, pred_val, average='macro')\n",
    "print(f\"Ensemble Validation Macro F1: {f1:.4f}\")\n",
    "\n",
    "# 测试集预测与保存\n",
    "proba_test = (2 * xgb_clf.predict_proba(X_test)\n",
    "             + 1 * lgb_clf.predict_proba(X_test)\n",
    "             + 1 * cat_clf.predict_proba(X_test)) / 4\n",
    "pred_test = np.argmax(proba_test, axis=1)\n",
    "pred_cat = le.inverse_transform(pred_test)\n",
    "pd.DataFrame({'id': test['id'], 'attack_cat': pred_cat}).to_csv(\n",
    "    'hetero_ensemble_predictions.csv', index=False\n",
    ")\n",
    "\n",
    "# 保存预处理器与模型\n",
    "joblib.dump(preprocessor, 'hetero_preprocessor.pkl')\n",
    "joblib.dump({'xgb': xgb_clf, 'lgb': lgb_clf, 'cat': cat_clf}, 'hetero_models.pkl')\n",
    "print(\"Heterogeneous ensemble results saved.\")\n"
   ],
   "id": "cce8ad7cffce77c7",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T05:18:32.977954Z",
     "start_time": "2025-05-17T05:16:57.942169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# ================== 数据预处理 ==================\n",
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data  = pd.read_csv('test_data.csv')\n",
    "\n",
    "classes = ['Generic','Reconnaissance','Normal','DoS','Fuzzers',\n",
    "           'Worms','Backdoor','Analysis','Shellcode','Exploits']\n",
    "\n",
    "# 特征工程函数\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    df['bytes_ratio']   = df['sbytes'] / (df['dbytes'] + 1e-6)\n",
    "    df['pkts_ratio']    = df['spkts'] / (df['dpkts'] + 1e-6)\n",
    "    df['flow_rate']     = (df['sbytes'] + df['dbytes']) / (df['dur'] + 1e-6)\n",
    "    df['pkt_size_diff'] = df['spkts'] - df['dpkts']\n",
    "    df['byte_per_pkt']  = (df['sbytes'] + df['dbytes']) / (df['spkts'] + df['dpkts'] + 1e-6)\n",
    "    df['total_bytes']   = df['sbytes'] + df['dbytes']\n",
    "    df['total_pkts']    = df['spkts'] + df['dpkts']\n",
    "    df['bytes_per_sec'] = df['total_bytes'] / (df['dur'] + 1e-6)\n",
    "    df['pkts_per_sec']  = df['total_pkts'] / (df['dur'] + 1e-6)\n",
    "    return df\n",
    "\n",
    "train_data = feature_engineering(train_data)\n",
    "test_data  = feature_engineering(test_data)\n",
    "\n",
    "# 分类特征替换\n",
    "categorical_cols = ['proto','service','state']\n",
    "for df in (train_data, test_data):\n",
    "    df[categorical_cols] = df[categorical_cols].replace('-', 'unknown')\n",
    "\n",
    "# 分离特征与标签\n",
    "X = train_data.drop(['id','attack_cat'], axis=1)\n",
    "y_raw = train_data['attack_cat']\n",
    "X_test = test_data.drop('id', axis=1)\n",
    "test_ids = test_data['id']\n",
    "\n",
    "# 标签编码\n",
    "le = LabelEncoder()\n",
    "y_mapped = y_raw.map(lambda x: x if x in classes else 'Normal')\n",
    "y = le.fit_transform(y_mapped)\n",
    "\n",
    "# 特征编码\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "], remainder='passthrough')\n",
    "X = preprocessor.fit_transform(X)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# 计算样本权重\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "sample_weights = class_weights[y]\n",
    "\n",
    "# 划分训练/验证集\n",
    "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(\n",
    "    X, y, sample_weights, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ================== 只使用 模型2 XGBoost 并加强 L1、L2 正则化 ==================\n",
    "params2 = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(classes),\n",
    "    'tree_method': 'hist',\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 10,\n",
    "    'min_child_weight': 2,\n",
    "    'gamma': 0.2,\n",
    "    # 强化正则化\n",
    "    'reg_alpha': 2.0,   # L1 正则化\n",
    "    'reg_lambda': 5.0,  # L2 正则化\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "# 构造 DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, weight=w_train)\n",
    "dval   = xgb.DMatrix(X_val,   label=y_val,   weight=w_val)\n",
    "\n",
    "# 训练模型\n",
    "model2 = xgb.train(\n",
    "    params2,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=50\n",
    ")\n",
    "\n",
    "# 验证评估\n",
    "pred_val = model2.predict(dval).astype(int)\n",
    "print(classification_report(y_val, pred_val, target_names=le.classes_))\n",
    "f1 = f1_score(y_val, pred_val, average='macro')\n",
    "print(f\"Model2 XGBoost Validation Macro F1: {f1:.4f}\")\n",
    "\n",
    "# 测试集预测与保存\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "pred_test = model2.predict(dtest).astype(int)\n",
    "pred_cat = le.inverse_transform(pred_test)\n",
    "result = pd.DataFrame({'id': test_ids, 'attack_cat': pred_cat})\n",
    "result.to_csv('model2_xgb_with_reg.csv', index=False)\n",
    "\n",
    "# 保存模型和预处理器\n",
    "joblib.dump(preprocessor, 'model2_preprocessor.pkl')\n",
    "model2.save_model('model2_xgb_with_reg.model')\n",
    "print(\"Model 2 XGBoost with L1 & L2 regularization saved.\")\n"
   ],
   "id": "67e99c4c8c895503",
   "execution_count": 9,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
